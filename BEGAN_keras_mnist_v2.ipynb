{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BEGAN_keras_mnist.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GTU7Tt50oAUu"},"source":["# BEGAN을 이용한 이미지생성"]},{"cell_type":"markdown","metadata":{"id":"KrNMDJkEsdnZ","colab_type":"text"},"source":["라이브러리 읽어들이기"]},{"cell_type":"code","metadata":{"id":"RwGecgAnpGPV","colab_type":"code","colab":{}},"source":["#https://drive.google.com/uc?export=download&id=1URxZOJTO38qb3v1hOT3usuAE7nTGQDnL\n","import os\n","\n","import numpy as np\n","from tensorflow.python import keras\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.keras import losses\n","from tensorflow.python.keras.optimizers import Adam\n","from tensorflow.python.keras.models import Sequential, Model\n","from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, Activation, Flatten, Dense, UpSampling2D, Reshape, Lambda, Input\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.preprocessing.image import img_to_array, array_to_img, load_img\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHgnAUROsf8m","colab_type":"text"},"source":["구글 드라이브 연동하기"]},{"cell_type":"code","metadata":{"id":"GxvN8vw6Br9z","colab_type":"code","outputId":"2403b9c3-c47d-47a1-ead0-72c0b8b3abc5","executionInfo":{"status":"ok","timestamp":1576210269659,"user_tz":-540,"elapsed":1419,"user":{"displayName":"김성신","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBDkcdDRtjexFDpgc5dOd19_nhgffecissjauBQWg=s64","userId":"05257912891226351338"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"57nBisFgszfP","colab_type":"text"},"source":["이미지를 저장하는 함수"]},{"cell_type":"code","metadata":{"id":"ubWsBcpoNIib","colab_type":"code","colab":{}},"source":["def save_imgs(path, imgs, rows, cols):\n","    \"\"\"이미지를 타일 형태로 저장\n","    \n","    Arguments:\n","        path (str): 저장할 폴더 경로\n","        imgs (np.array): 저장할 이미지 리스트\n","        rows (int): 타일의 세로 크기\n","        cols (int): 타일의 가로 크기\n","    \"\"\"\n","    base_width = imgs.shape[1]\n","    base_height = imgs.shape[2]\n","    channels = imgs.shape[3]\n","    output_shape = (\n","        base_height*rows,\n","        base_width*cols,\n","        channels\n","    )\n","    buffer = np.zeros(output_shape)\n","    for row in range(rows):\n","        for col in range(cols):\n","            img = imgs[row*cols + col]\n","            buffer[row*base_height:(row + 1)*base_height, col*base_width:(col + 1)*base_width] = img # 생성된 이미지 numpy 값을 버퍼에 저장        \n","    array_to_img(buffer).save(path) # numpy 배열값을 이미지로 변환한 후 /data/imgs 폴더에 저장 "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8UhYjeCtT4_","colab_type":"text"},"source":["이미지 데이터 읽어 들이기"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1576210269661,"user_tz":-540,"elapsed":1389,"user":{"displayName":"김성신","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBDkcdDRtjexFDpgc5dOd19_nhgffecissjauBQWg=s64","userId":"05257912891226351338"}},"id":"HM6HhYisP1QS","outputId":"6746ef4a-70ce-491a-f63e-d57166c1ad14","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["DATA_DIR = '/content/drive/My Drive/data/'\n","\n","BATCH_SIZE = 16\n","IMG_SHAPE = (28, 28, 3)\n","\n","data_gen = ImageDataGenerator(rescale=1/255.)\n","train_data_generator = data_gen.flow_from_directory(\n","    directory=DATA_DIR,\n","    classes=['mnist'],\n","    class_mode=None,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMG_SHAPE[:2]\n",")"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Found 96 images belonging to 1 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ckxw89vJtXfe","colab_type":"text"},"source":["Encoder 정의"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yubnwEo77Z0l","colab":{}},"source":["def build_encoder(input_shape, z_size, n_filters, n_layers):\n","    \"\"\"Encoder구축\n","    \n","    Arguments:\n","        input_shape (int): 이미지의 shape\n","        z_size (int): 특징 공간의 차원 수\n","        n_filters (int): 필터 수\n"," \n","    \"\"\"\n","    model = Sequential()\n","    model.add(Conv2D(3, 3, activation='elu',input_shape=input_shape, padding='same'))\n","    model.add(Conv2D(n_filters, 3, padding='same'))\n","    for i in range(2, n_layers + 1):\n","        model.add(Conv2D(i*n_filters, 3, activation='elu',padding='same'))\n","        model.add(Conv2D(i*n_filters, 3, activation='elu',strides=2,padding='same'))\n","  \n","    model.add(Conv2D(n_layers*n_filters, 3, padding='same'))\n","    model.add(Flatten())\n","    model.add(Dense(z_size))\n","    model.summary()\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PIZ-LGUTpcfm","colab_type":"text"},"source":["생성자(Generator)/Decoder 정의"]},{"cell_type":"code","metadata":{"id":"eQtdcSemUDg8","colab_type":"code","colab":{}},"source":["def build_decoder(output_shape, z_size, n_filters, n_layers):\n","    \"\"\"Decoder 구축\n","    \n","    Arguments:\n","        output_shape (np.array): 이미지 shape\n","        z_size (int): 특징 공간의 차원 수\n","        n_filters (int): 필터 수\n","        n_layers (int): 레이어 수\n","\n","    \"\"\"\n","    # UpSampling2D로 몇 배로 확대할지 계산\n","    scale = 2**(n_layers - 1)\n","    # 합성곱층의 처음 입력 사이즈를 scale로부터 역산\n","    fc_shape = (output_shape[0]//scale, output_shape[1]//scale, n_filters )\n","    # 완전연결 계층에서 필요한 사이즈를 역산\n","    fc_size = fc_shape[0]*fc_shape[1]*fc_shape[2]\n","    \n","    model = Sequential()\n","    # 완전연결 계층\n","    model.add(Dense(fc_size, input_shape=(z_size,)))\n","    model.add(Reshape(fc_shape))\n","    \n","    # 합성곱층 반복\n","    for i in range(n_layers - 1):\n","        model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n","        model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n","        model.add(UpSampling2D())\n","        \n","    # 마지막 층은 UpSampling2D가 불필요 \n","    model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n","    model.add(Conv2D(n_filters, 3, activation='elu', padding='same'))\n","    # 출력층에서는 3채널로\n","    model.add(Conv2D(3, 3, padding='same'))\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62pqShRxqr3C","colab_type":"text"},"source":["생성자(Generator) 정의"]},{"cell_type":"code","metadata":{"id":"C9WoQlbDUHWa","colab_type":"code","colab":{}},"source":["def build_generator(img_shape, z_size, n_filters, n_layers):\n","    decoder = build_decoder(img_shape, z_size, n_filters, n_layers)\n","    return decoder"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWmR4YIUqO_a","colab_type":"text"},"source":["구분자(Discriminator) 정의"]},{"cell_type":"code","metadata":{"id":"BEjyU_G7UJ65","colab_type":"code","colab":{}},"source":["def build_discriminator(img_shape, z_size, n_filters, n_layers):\n","    encoder = build_encoder(img_shape, z_size, n_filters, n_layers)\n","    decoder = build_decoder(img_shape, z_size, n_filters, n_layers)\n","    return keras.models.Sequential((encoder, decoder))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0tUlFHFcrbWf","colab_type":"text"},"source":["구분자(Discriminator) 학습용 네트워크"]},{"cell_type":"code","metadata":{"id":"bDCKW3QMURHz","colab_type":"code","colab":{}},"source":["def build_discriminator_trainer(discriminator):\n","    img_shape = discriminator.input_shape[1:]\n","    real_inputs = Input(img_shape)\n","    fake_inputs = Input(img_shape)\n","    real_outputs = discriminator(real_inputs)\n","    fake_outputs = discriminator(fake_inputs)\n","\n","    return Model(\n","        inputs=[real_inputs, fake_inputs],\n","        outputs=[real_outputs, fake_outputs]\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEOgJ0gxuTX1","colab_type":"text"},"source":["네트워크 구축"]},{"cell_type":"code","metadata":{"id":"oeyQKz3nuUjM","colab_type":"code","outputId":"7f19e849-18f0-4772-e544-46a54e4686d2","executionInfo":{"status":"ok","timestamp":1576210270549,"user_tz":-540,"elapsed":2227,"user":{"displayName":"김성신","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBDkcdDRtjexFDpgc5dOd19_nhgffecissjauBQWg=s64","userId":"05257912891226351338"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["n_filters = 64  #  필터 수\n","n_layers = 3 # 레이어 수\n","z_size = 32  #  특징 공간의 차원\n","\n","generator = build_generator(IMG_SHAPE, z_size, n_filters, n_layers)\n","discriminator = build_discriminator(IMG_SHAPE, z_size, n_filters, n_layers)\n","discriminator_trainer = build_discriminator_trainer(discriminator)\n","\n","generator.summary()\n","\n","# discriminator.layers[1]은 디코더를 나타냄\n","discriminator.layers[1].summary()"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_49 (Conv2D)           (None, 28, 28, 3)         84        \n","_________________________________________________________________\n","conv2d_50 (Conv2D)           (None, 28, 28, 64)        1792      \n","_________________________________________________________________\n","conv2d_51 (Conv2D)           (None, 28, 28, 128)       73856     \n","_________________________________________________________________\n","conv2d_52 (Conv2D)           (None, 14, 14, 128)       147584    \n","_________________________________________________________________\n","conv2d_53 (Conv2D)           (None, 14, 14, 192)       221376    \n","_________________________________________________________________\n","conv2d_54 (Conv2D)           (None, 7, 7, 192)         331968    \n","_________________________________________________________________\n","conv2d_55 (Conv2D)           (None, 7, 7, 192)         331968    \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 9408)              0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 32)                301088    \n","=================================================================\n","Total params: 1,409,716\n","Trainable params: 1,409,716\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_6 (Dense)              (None, 3136)              103488    \n","_________________________________________________________________\n","reshape_4 (Reshape)          (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","conv2d_42 (Conv2D)           (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","conv2d_43 (Conv2D)           (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","up_sampling2d_8 (UpSampling2 (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_44 (Conv2D)           (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","conv2d_45 (Conv2D)           (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","up_sampling2d_9 (UpSampling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_46 (Conv2D)           (None, 28, 28, 64)        36928     \n","_________________________________________________________________\n","conv2d_47 (Conv2D)           (None, 28, 28, 64)        36928     \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 28, 28, 3)         1731      \n","=================================================================\n","Total params: 326,787\n","Trainable params: 326,787\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_8 (Dense)              (None, 3136)              103488    \n","_________________________________________________________________\n","reshape_5 (Reshape)          (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","conv2d_56 (Conv2D)           (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","conv2d_57 (Conv2D)           (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","up_sampling2d_10 (UpSampling (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_58 (Conv2D)           (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","conv2d_59 (Conv2D)           (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","up_sampling2d_11 (UpSampling (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_60 (Conv2D)           (None, 28, 28, 64)        36928     \n","_________________________________________________________________\n","conv2d_61 (Conv2D)           (None, 28, 28, 64)        36928     \n","_________________________________________________________________\n","conv2d_62 (Conv2D)           (None, 28, 28, 3)         1731      \n","=================================================================\n","Total params: 326,787\n","Trainable params: 326,787\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"swBw2e0GrwwK","colab_type":"text"},"source":["손실(loss) 함수 정의"]},{"cell_type":"code","metadata":{"id":"nMKo8Nz7UXmk","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.losses import mean_absolute_error\n","\n","def build_generator_loss(discriminator):\n","    # discriminator를 사용해서 손실 함수 정의\n","    def loss(y_true, y_pred):\n","        # y_true는 더미\n","        reconst = discriminator(y_pred)\n","        return mean_absolute_error(reconst, y_pred)\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6CWx0rtDr0tU","colab_type":"text"},"source":["generator 컴파일"]},{"cell_type":"code","metadata":{"id":"8UGijY_BUaxT","colab_type":"code","colab":{}},"source":["# 초기 학습률(Generator)\n","g_lr = 0.0001\n","\n","generator_loss = build_generator_loss(discriminator)\n","generator.compile(loss=generator_loss, optimizer=Adam(g_lr))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7J0c9Owr4DC","colab_type":"text"},"source":["\n","discriminator 컴파일"]},{"cell_type":"code","metadata":{"id":"pRpY820HZRCg","colab_type":"code","colab":{}},"source":["# 초기 학습률(Discriminator)\n","d_lr = 0.0001\n","# k_var는 수치(일반 변수)\n","k_var = 0.0\n","# k : Keras(TensorFlow) Variable\n","k = K.variable(k_var)\n","\n","discriminator_trainer.compile(loss=[ mean_absolute_error, mean_absolute_error],loss_weights=[1., -k], optimizer=Adam(d_lr))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgZMurL_sCIC","colab_type":"text"},"source":["수렴 판정용 함수 정의"]},{"cell_type":"code","metadata":{"id":"I-R5uIGhsIKJ","colab_type":"code","colab":{}},"source":["def measure(real_loss, fake_loss, gamma):\n","    return real_loss + np.abs(gamma*real_loss - fake_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bpIuIlQBsMaT","colab_type":"text"},"source":["학습 코드"]},{"cell_type":"code","metadata":{"id":"cwMoUzxiZiY4","colab_type":"code","outputId":"d4e4541e-0ebf-4864-9b9a-1accfca35b05","executionInfo":{"status":"ok","timestamp":1576210336619,"user_tz":-540,"elapsed":59202,"user":{"displayName":"김성신","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBDkcdDRtjexFDpgc5dOd19_nhgffecissjauBQWg=s64","userId":"05257912891226351338"}},"colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["# k의 갱신에 이용할 파라미터\n","GAMMA = 0.5\n","Lambda = 0.001\n","\n","# 모델과 확인용 생성 이미지를 저장할 폴더\n","\n","IMG_SAVE_DIR = '/content/drive/My Drive/data/imgs'\n","# 확인용으로 5x5 개의 이미지를 생성\n","IMG_SAMPLE_SHAPE = (4, 4)\n","N_IMG_SAMPLES = np.prod(IMG_SAMPLE_SHAPE)\n","\n","\n","# 저장할 폴더가 없다면 생성\n","os.makedirs(IMG_SAVE_DIR, exist_ok=True)\n","\n","# 샘플이미지용 랜덤 시드\n","sample_seeds = np.random.uniform(-1, 1, (N_IMG_SAMPLES, z_size))\n","\n","history = []\n","logs = []\n","\n","for step, batch in enumerate(train_data_generator): \n","\n","    #임의의 값(noise) 생성, 잠재변수의 input으로 사용할 noise를 균등분포(Uniform Distribution)에서 BATCH_SIZE만큼 샘플링\n","    noise = np.random.uniform(-1, 1, (BATCH_SIZE, z_size))  # 균등 분포 -1과 1사이에 랜덤값 추출\n","     \n","    # 생성 이미지(구분자의 학습에 이용), noise를 입력받아 가짜 이미지 생성\n","    g_pred = generator.predict(noise)\n","    \n","    # 생성자를 1스텝 학습시킨다\n","    generator.train_on_batch(noise, batch)\n","    # discriminator 1스텝 학습시킨다\n","    _, real_loss, fake_loss = discriminator_trainer.train_on_batch([batch, g_pred],[batch, g_pred]) \n","\n","    # k 를 갱신, generator & discriminator loss 균형맞춤. discriminator가 얼마나  fake images에 집중할 것인지 컨트롤. 매 batch마다 업데이트.\n","    k_var += Lambda*(GAMMA*real_loss - fake_loss)\n","    K.set_value(k, k_var)\n","    \n","\n","    # g_measure 을 계산하기 위한 loss 저장\n","    history.append({'real_loss': real_loss,'fake_loss': fake_loss })\n","\n","    # 100번에 1번씩 로그 표시\n","    if step%100 == 0:\n","        # 과거 10 번의 measure 의 평균\n","        measurement = np.mean([measure(loss['real_loss'],loss['fake_loss'],GAMMA) for loss in history[-100:]])\n","        \n","        logs.append({'k': K.get_value(k),'measure': measurement,'real_loss': real_loss,'fake_loss': fake_loss })\n","        print(logs[-1])\n","\n","        # 생성된 이미지 저장  \n","        img_path = '{}/generated_{}.png'.format(IMG_SAVE_DIR, step)\n","        save_imgs(img_path, generator.predict(sample_seeds), rows=IMG_SAMPLE_SHAPE[0], cols=IMG_SAMPLE_SHAPE[1])"],"execution_count":87,"outputs":[{"output_type":"stream","text":["{'k': 1.0330525e-05, 'measure': 0.1427174173295498, 'real_loss': 0.1323869, 'fake_loss': 0.055862922}\n","{'k': 0.003242712, 'measure': 0.14074447454884648, 'real_loss': 0.09345691, 'fake_loss': 0.018001722}\n","{'k': 0.0055934777, 'measure': 0.10588674920611084, 'real_loss': 0.07874434, 'fake_loss': 0.014894912}\n","{'k': 0.007856384, 'measure': 0.09530952670611441, 'real_loss': 0.063705996, 'fake_loss': 0.013160951}\n","{'k': 0.009866415, 'measure': 0.08807622592896223, 'real_loss': 0.07291008, 'fake_loss': 0.0140133565}\n","{'k': 0.011609498, 'measure': 0.08190130028873682, 'real_loss': 0.06034153, 'fake_loss': 0.01545805}\n","{'k': 0.013035979, 'measure': 0.07582621318288148, 'real_loss': 0.059932806, 'fake_loss': 0.016580595}\n","{'k': 0.014079904, 'measure': 0.06853405756875873, 'real_loss': 0.053667784, 'fake_loss': 0.016954133}\n","{'k': 0.014864711, 'measure': 0.06094418005086481, 'real_loss': 0.049864154, 'fake_loss': 0.019179137}\n","{'k': 0.015570703, 'measure': 0.05404318572022021, 'real_loss': 0.04448845, 'fake_loss': 0.016786812}\n","{'k': 0.016169354, 'measure': 0.048602700056508186, 'real_loss': 0.03987706, 'fake_loss': 0.015268798}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VC8lpmqqrST-"},"source":[""]}]}